\section{Filtro de Kalman}\label{sec:kalman}

% Una vez que se tiene el modelo, si se quiere aplicar a un contexto específico, es necesario incorporar los datos para ajustar los parámetros. Dos técnicas conocidas y ampliamente utilizadas para esto son, por una parte, resolver el problema de minimización de una función de costo dada por la diferencia entre los valores dados por el modelo y las observaciones, sobre los posibles parámetros. Por otra parte, es posible seguir un enfoque bayesiano, asignando densidades a priori a cada parámetro y luego usando los datos para actualizar esas densidades mediante el método de Monte Carlo. Una posibilidad menos explorada es la asimilación de datos usando el Filtro de Kalman.

Filtro de Kalman es un método ampliamente utilizado en diversas aplicaciones de ingeniería como navegación, control de vehículos, procesamiento de señales, etc \cite{Auger2013}. Se tiene un sistema cuya evolución está dada por ciertas ecuaciones. El estado del sistema es desconocido pero se cuenta con observaciones ruidosas de este. El objetivo es estimar el estado a partir de estas observaciones; por ejemplo, estimar la posición de un vehículo cuando solo se conoce su velocidad.

Para un instante \(k\)-ésimo, hay tres formas importantes de estimación del estado \(x_k\) del sistema. El suavizado (\emph{smoothing}) intenta obtener la mejor estimación posible de \(x_k\) usando la información, es decir las observaciones, disponibles hasta un instante posterior \(k+m\). El filtraje solo dispone de información hasta la iteración \(k\)-ésima, y la predicción tiene información hasta una iteración anterior \(k-m\). Debido a la cantidad de información que conoce, el suavizado desde luego debería dar el mejor resultado de los tres, seguido por el filtraje y finalmente la predicción. 

Si bien en su versión original el filtro de Kalman estaba enfocado en un problema lineal gaussiano \cite{Kalman1960}, han surgido diversas variantes para generalizarlo a otros problemas. Algunas de las más conocidas son el Filtro de Kalman Extendido (EKF) o el Filtro ``sin olor'' \textit{Unscented} (UKF) \cite{Cai2006}, que permiten trabajar con sistemas no lineales, el Filtro de Kalman por Ensambles (EnKF) \cite{Katzfuss2016}, que es menos costoso computacionalmente y que puede usarse en problemas con gran cantidad de estados, o el Filtro H\(^\infty\) que es más robusto ante incertezas en el modelo. Varios de estos filtros tienen versiones continuas y discretas \cite{Kulikov2014}.

Esta sección está fuertemente basada en \cite{Anderson2005} y \cite{Simon2006}, y se estructura como sigue: en la subsección \ref{filtro-lineal} comenzaremos estudiando en detalle el filtro de Kalman para el caso más sencillo, en que el sistema es lineal y gaussiano. A continuación, la subsección \ref{filtro-extendido} presenta el Filtro de Kalman Extendido, una variante que permite trabajar con sistemas no lineales, y que es la que usaremos en el trabajo.

Finalmente se exponen algunas técnicas que serán de utilidad. La subsección \ref{estimacion-de-parametros} muestra una forma de estimar parámetros desconocidos de la dinámica del sistema. La subsección \ref{casiperfect} muestra una forma de incorporar restricciones a las estimaciones, y la subsección \ref{smoother} se aparta del filtraje para presentar una forma de suavizado cuando son conocidas todas las observaciones para un intervalo de tiempo.

\subsection{Filtro de Kalman lineal discreto}\label{filtro-lineal}

Para comenzar a explicar el filtro de Kalman, se decide utilizar un caso sencillo. Se tiene un sistema como el de la ecuación \ref{eq:kalman-lineal-discreto}, donde \(x_k \in \mathbb{R}^{n}\) y \(F_k, G_k \in \mathbb{R}^{n \times n}\) y \(w_k \sim \mathcal{N}(0,Q_k)\) es un vector aleatorio que representa un ruido gaussiano en la dinámica del sistema. 

\begin{equation}\label{eq:kalman-lineal-discreto}
x_{k+1} = F_k x_k + G_k w_k.
\end{equation}

Los estados \(x_k\) del sistema son desconocidos, y solo es posible conocer observaciones \(y_k\) de ellos, dadas por la ecuación \ref{eq:kalman-lineal-discreto-obs}, donde \(y_k \in \mathbb{R}^{m}, H_k \in \mathbb{R}^{m \times n}\) y \( v_k \sim \mathcal{N}(0, R_k)\) representa un ruido gaussiano en las observaciones.

\begin{equation}\label{eq:kalman-lineal-discreto-obs}
y_k = H_k x_k  + v_k.
\end{equation}


Para una condición inicial gaussiana \(x_0 \sim \mathcal{N}(\hat{x}_0, P_0)\), la linealidad del sistema y el hecho de que el ruido es gaussiano, implica que cada uno de los \(x_k\) serán también gaussianos. Se busca estimar \(x_k\) a partir de las observaciones \(y_k\). Más específicamente, en términos bayesianos, se busca la distribución \textit{a posteriori} de \(x_k\) dado un conjunto de observaciones \(y_{1:l} := \{y_1, \dots, y_l\}\). Denotaremos a esta distribución \(x_{k,l}:= x_k | y_{1:l}\).

Existen tres formas de estimación, que dependen del valor de \(l\); en primer lugar, si \(l < k\), se está intentando estimar \(x_k\) con información hasta un instante \(l\) anterior a \(k\). A esta forma se le llama predicción o \textit{forecasting}. En segundo lugar, si \(l>k\), entonces se está estimando \(x_k\) con información hasta un instante \(l\) posterior a \(k\). Se llamará a esto suavizado o \textit{smoothing}. Finalmente, si \(l = k\) se llamará filtraje o \textit{filtering}. Es esta última forma la que nos presenta mayor interés y que facilita la explicación, por lo que es la forma que será utilizada.

Se sigue el siguiente procedimiento. Se comienza suponiendo que la distribución a posteriori de \(x_{k-1}\) con observaciones hasta el instante \(k-1\) es conocida, \(x_{k-1, k-1} \sim \mathcal{N}(\hat{x}_{k-1, k-1}, P_{k-1, k-1})\); se busca la distribución \(x_{k, k}\). Esto se logra mediante una iteración del filtro de Kalman, la cual se divide en dos etapas; una de predicción, que usa la dinámica para obtener \(x_{k+1, k}\), y una de análisis, que incorpora \(y_k\) para obtener \(x_{k, k}\).

La propiedad \ref{prop:conj-gauss-cond}, cuya demostración puede leerse en \cite{Anderson2005} y que ocupa el Teorema de Bayes, será útil a la hora de hacer los cálculos.


\begin{prop}
\label{prop:conj-gauss-cond}
Sean \(X, Y\) vectores aleatorios conjuntamente
gaussianos, ie. tal que

\[
Z := \begin{pmatrix}
X\\
Y
\end{pmatrix} \sim \mathcal{N}\left(
\begin{pmatrix}
\bar{x} \\
\bar{y}
\end{pmatrix}, 
\begin{pmatrix}
\Sigma_{xx} & \Sigma_{xy} \\
\Sigma_{yx} & \Sigma_{yy}
\end{pmatrix}
\right).
\] Entonces \[
(X|Y=y) \sim \mathcal{N} \left( \bar{x} + \Sigma_{xy}\Sigma_{yy}^{-1}(y-\bar{y}),
\Sigma_{xx} - \Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx}
 \right).
\]
\end{prop}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  En el paso de predicción se hace una suposición \emph{a priori} de dónde estará el estado real en la próxima iteración a partir de la dinámica y de la estimación actual, sin utilizar la observación \(y_k\). Usando que \(x_{k-1,k-1} \sim \mathcal{N}(\hat{x}_{k-1,k-1}, P_{k-1,k-1})\), y la ecuación \ref{eq:kalman-lineal-discreto}, no es difícil ver que \(x_{k,k-1} \sim \mathcal{N}(\hat{x}_{k,k-1}, P_{k,k-1})\), con 
    \begin{equation}
    \begin{aligned}
    \hat{x}_{k,k-1} &= F_{k-1} \hat{x}_{k-1,k-1} \\
    %P_{k,n-1} &= M_k P_{k-1,n-1} M_k^{\top} + F_k Q_k F_k^{\top}
    P_{k,k-1} &= F_{k-1} P_{k-1,k-1} F_{k-1}^{\top} + G_k Q_k G_k^T.
    \end{aligned}
    \end{equation}
\item
  En el paso de análisis, se incorpora la observación \(y_k\) para obtener una estimación \emph{a posteriori}. Para esto basta con usar la proposición \ref{prop:conj-gauss-cond}, calculando la distribución conjunta de \(x_k\) e \(y_k\) dado \(y_{1:k}\), para obtener la expresión \ref{eq:conjunta}. La propiedad \ref{prop:conj-gauss-cond} nos permite decir que \(
    x_{k,k} \sim
     \mathcal{N} \left( \hat{x}_{k,k}, P_{k,k} \right)
    \), con \(\hat{x}_{k,k}\) y \(P_{k,k}\) definidos en las ecuaciones \ref{eq:terminos-raros}.
  
    \begin{equation}\label{eq:conjunta}
    \begin{pmatrix}
    x_k \\
    y_k
    \end{pmatrix} \Big| y_{1:k} \sim \mathcal{N}\left(
    \begin{pmatrix}
    \hat{x}_{k, k-1} \\
    H_k \hat{x}_{k,k-1}
    \end{pmatrix},
    \begin{pmatrix}
    P_{k,k-1} & P_{k,k-1} H^T_{k}\\
    H_{k}P_{k,k-1}  & H_{k}P_{k,k-1}H_{k}^T + R_k
    \end{pmatrix}  
    \right),
    \end{equation}

    \begin{equation}\label{eq:terminos-raros}
    \begin{aligned}
    K_k &= P_{k,k-1} H^{\top}_{k}(H_{k}P_{k,k-1}H_{k}^{\top} + R_k)^{-1}\\
    \hat{x}_{k,k} &= \hat{x}_{k, k-1} + K_k(y_k-H_k \hat{x}_{k,k-1}) \\
    P_{k,k} &= P_{k,k-1}- K_k H_{k}P_{k,k-1}. \\
    \end{aligned}
    \end{equation}
\end{enumerate}
Estos dos pasos de predicción y análisis entregan una regla que permite iterar; basta con definir la condición inicial como \(\hat{x}_{0,-1} := x_0\), \(P_{0,-1} := P_0\). El Teorema \ref{teo:min-var}, cuya demostración está en \cite{Anderson2005}, asegura que los valores \(\hat{x}_{k,k}\) son estimadores de mínima varianza para \(x_{k,k}\).

\begin{teo}
\label{teo:min-var}
Sean \(X, Y\) vectores aleatorios conjuntamente gaussianos. Sea también \(\hat{x} := \mathbb{E}(X|Y=y)\). Entonces \(\hat{x}\) es un
\emph{estimador de mínima varianza}, es decir, satisface

\[
\mathbb{E}(\| X - \hat{x}\|^2 | Y = y) \leq \mathbb{E}(\| X - z\|^2 | Y = y) \quad \forall z
\]
\end{teo}


\begin{mdframed}[style=mystyle,frametitle=Filtro de Kalman Lineal Discreto]

Para el caso lineal discreto como el presentado por las ecuaciones \ref{eq:system-ecs}, el filtro de Kalman se define como \ref{eq:kalman-final}, donde \(\hat{x}_{0,-1}:= x_0\) y \(P_{0,-1}:= P_0\). Los valores \(\hat{x}_{k,k}\) son estimadores de mínima varianza de \(x_{k,k}\). 

\begin{equation}\label{eq:system-ecs}
\begin{aligned}
x_{k+1} &= M_k x_k + F_k w_k \\ 
y_k &= H_k x_k + v_k.
\end{aligned}
\end{equation}


\begin{equation}\label{eq:kalman-final}
\begin{aligned}
\hat{x}_{k,k-1} &= F_{k-1} \hat{x}_{k-1,k-1} \\
P_{k,k-1} &= F_{k-1} P_{k-1,k-1} F_{k-1}^{\top} + G_{k-1} Q_{k-1} G_{k-1}^{\top}\\
K_k &= P_{k,k-1} H^{\top}_{k}(H_{k}P_{k,k-1}H_{k}^{\top} + R_k)^{-1}\\
\hat{x}_{k,k} &= \hat{x}_{k, k-1} + K_k(y_k-H_k \hat{x}_{k,k-1}) \\
P_{k,k} &= P_{k,k-1}- K_k H_{k}P_{k,k-1}. \\
\end{aligned}
\end{equation}

\end{mdframed}


% {[}Agregar recuadro con la variante que incorpora un control conocido{]}

% Similarmente, para el modelo 
% \[
% \begin{aligned}
% x_{k+1} &= M_k x_k + B_k u_k + F_k N_k \\ 
% y_k &= H_k x_k + v_k
% \end{aligned}
% \]

% Las ecuaciones correspondientes son 

% {[}Agregar un ejemplo y algún gráfico, para hacerse una idea de cómo funciona{]}

\subsection{Filtro de Kalman Extendido (EKF)}\label{filtro-extendido}

% agregar más intro

El filtro de Kalman Extendido permite trabajar con sistemas no lineales. Se trabaja ahora con un modelo como el dado por las ecuaciones \ref{eq:nl-model}, donde las funciones \(f_k, g_k, h_k\) son posiblemente no lineales. 

\begin{equation}\label{eq:nl-model}
\begin{aligned}
x_{k+1} &= f_k(x_k, t_k) + g_k(x_k, t_k) w_k \\
y_{k} &= h(x_k, t_k) + v_k.
\end{aligned}
\end{equation}

Usando la notación de las ecuaciones \ref{eq:taylor-notation}, es posible definir el filtro de Kalman Extendido como en \ref{eq:kalman-extended}. A diferencia del caso lineal, este ya no es óptimo.

\begin{equation}\label{eq:taylor-notation}
\begin{aligned}
F_k := \left. \frac{\partial f_k(x, t)}{\partial x} \right|_{\substack{x = \hat{x}_{k,k} \\ t = t_k }} & H_k := \left. \frac{\partial h_k(x, t)}{\partial x} \right|_{\substack{x = \hat{x}_{k,k} \\ t = t_k }} & G_k := g_k(\hat{x}_{k,k}, t_k).
\end{aligned}
\end{equation}


% \begin{equation}\label{eq:decomposition}
% \begin{aligned}
% f_k(x_k, t_k) &= f_k(\hat{x}_{k,k}, t_k) + F_k(x_k - \hat{x}_{k,k}) + \dots \\
% g_k(x_k, t_k) &= g_k(\hat{x}_{k,k}, t_k) + \dots = G_k + \dots \\
% h_k(x_k, t_k) &= f_k(\hat{x}_{k,k}, t_k) + H_k(x_k - \hat{x}_{k,k}) + \dots \\
% \end{aligned}
% \end{equation}

% Despreciando los términos de mayor orden, y suponiendo conocidos \(\hat{x}_{k,k}\) y \(\hat{x}_{k,k-1}\), es posible aproximar el sistema como en las ecuaciones \ref{eq:ekf-aprox}.

% \begin{equation}\label{eq:ekf-aprox}
% \begin{aligned}
% x_{k+1} &= F_k x_k + G_k w_k + \overbrace{f_k(\hat{x}_{k,k}) - F_k \hat{x}_{k,k}}^{u_k} \\
% y_{k} &= H_k x_k + v_k + \underbrace{h_k(\hat{x}_{k,k-1}) - H_k \hat{x}_{k,k-1}}_{z_k}
% \end{aligned}
% \end{equation}


\begin{mdframed}[style=mystyle,frametitle=Filtro de Kalman Extendido (EKF)]

Para el caso lineal discreto como el presentado por las ecuaciones \ref{eq:nl-model}, el filtro de Kalman Extendido se define como \ref{eq:kalman-extended}, donde \(\hat{x}_{0,-1}:= x_0\) y \(P_{0,-1}:= P_0\). 

\begin{equation}\label{eq:kalman-extended}
\begin{aligned}
\hat{x}_{k,k-1} &= f_{k-1}( \hat{x}_{k-1,k-1}, t_{k-1}) \\
P_{k,k-1} &= F_{k-1} P_{k-1,k-1} F_{k-1}^{\top} + G_{k-1} Q_{k-1} G_{k-1}^{\top}\\
K_k &= P_{k,k-1} H^{\top}_{k}(H_{k}P_{k,k-1}H_{k}^{\top} + R_k)^{-1}\\
%z_k &= h_k(\hat{x}_{k,k-1}) - H_k \hat{x}_{k,k-1} \\
\hat{x}_{k,k} &= \hat{x}_{k, n-1} + K_k(y_k-h_k(\hat{x}_{k,k-1}, t_k)) \\
P_{k,k} &= P_{k,k-1}- K_k H_{k}P_{k,k-1}. \\
\end{aligned}
\end{equation}
\end{mdframed}


% \subsection{Filtro continuo-discreto}\label{filtro-continuo-discreto}

% \cite{Kulikov2017} Queremos seguir extendiendo la idea anterior. Supondremos ahora que nuestro sistema es continuo y está definida por una ecuación diferencial estocástica de la forma 

% \[
% dx(t) = f(t, x(t))dt + g(t)dw(t)
% \]

% donde \(w(t)\) es un proceso browniano con matriz de difusión \(Q(t)\). Las observaciones son discretas y llegan cada intervalos de largo \(\delta := t_k - t_{k-1}\). Llamaremos a \(\delta\) \textit{tiempo de muestreo}. 

% Para poder usar las variantes anteriores es necesario discretizar la ecuación. Hay dos opciones; es posible linealizar primero y luego discretizar, dando lugar al filtro extendido \textit{continuo-discreto} (CD-EKF), o discretizar y luego linealizar, a lo que se llama filtro \textit{discreto-discreto}. Nos interesa el primer caso. 

% Obtendremos la siguiente Ecuación Diferencial Ordinaria (EDO) 
% \[
% \begin{aligned}
% \frac{d\hat{x}}{dt} &= f(t, \hat{x}) \\ 
% \frac{dP}{dt} &= \frac{\partial f(t, \hat{x})}{\partial \hat{x}} P + P \left( \frac{\partial f(t, \hat{x})}{\partial \hat{x}} \right)^{\top} + g(t)Q(t)g(t)^{\top} \\ 
% \end{aligned}
% \]
% la que tendremos que resolver en el intervalo \([t_{k-1}, t_{k}]\) con las condiciones iniciales \(\hat{x}(t_{k-1}) = \hat{x}_{k-1, n-1}, P(t_{k-1}) = P_{k-1, n-1}\), para luego definir \(\hat{x}_{k,n-1} := \hat{x}(t_k), P_{k,n-1} := P(t_k)\). El paso de análisis permanece sin cambios. 

% Notamos que este enfoque tiene dos problemas importantes; la ecuación debe ser tratada numéricamente, lo que introduce un error de discretización adicional. La segunda se relaciona con la semipositividad de la matriz \(P(t_k)\), la cual no está garantizada.

% \subsection{Filtro por ensambles}\label{filtro-por-ensambles}

% Esta sección está basada en \cite{Katzfuss2016}.

% El filtro de Kalman por ensambles (\textbf{EnKF} por su nombre en inglés \emph{Ensemble Kalman Filter}), es una versión aproximada del filtro de Kalman, donde la distrubución del estado se representa con una muestra o
% ``ensamble'' de esa distribución .

% Más específicamente, suponemos que \(\hat{x}^{(1)}_{k,n}, \dots, \hat{x}^{(N)}_{k,n}\) es una muestra de la distribución filtrada en tiempo \(k\), es decir, que \(\hat{x}^{(i)}_{k,n} \sim \mathcal{N}(\hat{x}_{k,n}, P_{k,n})\).

% Al igual que con el filtro de Kalman, una iteración de EnKF también se hará en un paso de \emph{forecast} y un paso de análisis.

% Durante el \emph{forecast}, nuestra distribución a priori será

% \[
% \hat{x}^{(i)}_{k+1,n} = f_k(\hat{x}^{(i)}_{k,n}, u_k, w^{(i)}_k)
% \]

% con \(w^{(i)}_k \sim \mathcal{N}(0,Q_k)\). Para el caso lineal en que \(f_k(x, u, w) = M_k x + B_k u + w\) se puede verificar que
% \(\hat{x}^{(i)}_{k+1,n} \sim \mathcal{N}(\mu, \Sigma)\) (COMPLETAR).

\subsection{Estimación de
parámetros: estado aumentado}\label{estimacion-de-parametros}

Hasta ahora hemos trabajado con el supuesto de que las únicas cantidades desconocidas eran los vectores \(x_k\). Sin embargo, la mayoría de las veces tendremos además parámetros desconocidos \(p\), los cuales también necesitan ser estimados. Este apartado está basado en la sección 13.4 de \cite{Simon2006}.

Se tiene un sistema donde las matrices dependen de forma no lineal de cierto parámetro desconocido \(p\), como se ve en las ecuaciones \ref{eq:model-p}.

\begin{equation}\label{eq:model-p}
\begin{aligned}
x_{k+1} &= F_k(p)(x_k) + G_k(p)w_k \\
y_{k} &= H_k x_k + v_k. \\ 
\end{aligned}
\end{equation}

Por simplicidad no se agregó dependencia de \(p\) a las mediciones, pero es un caso que puede extenderse de manera sencilla a partir de este. Para estimar \(p\) se define un estado aumentado \(x'\) como en \ref{eq:estado-aumentado}. Bajo el supuesto de que \(p\) es constante, se usa la dinámica \(p_{k+1} = p_k + w_{pn}\). El ruido \(w_{pn}\) artificial permitirá al filtro cambiar su estimación de \(p_k\). Finalmente, el sistema aumentado está dado por las ecuaciones \ref{eq:sistema-aumentado}.

\begin{equation}\label{eq:estado-aumentado}
x'_k = \begin{bmatrix}x_k \\ p_k \end{bmatrix}.
\end{equation}

\begin{equation}\label{eq:sistema-aumentado}
\begin{aligned}
x'_{k+1} &= \begin{bmatrix} F_k(p_k)(x_k) + G_k(p_k)w_k \\ p_k + w_{pn} \end{bmatrix} \\
&= f(x'_{k}, w_k, w_{kp}) \\
y_{k} &= \begin{bmatrix} H_k & 0 \end{bmatrix} \begin{bmatrix}x_k \\ p_k \end{bmatrix} + v_k. \\ 
\end{aligned}
\end{equation}

\(f(x'_{k}, w_k, w_{kp}) \) es una función no lineal en el estado aumentado \(x'_k\), por lo que se puede estimar \(x'_k\) a partir de algún filtro no lineal como EKF.

% Mostrar que es posible que el filtro converja a valores erróneos, ver cómo eso depende de los errores que se le dan al filtro.

\subsection{Suavizado: \textit{RTS smoother}} \label{smoother}

% Hay tres variantes de smoothing, pero a mí solo me interesa una. Las otras creo que solo las mencionaré 

% Un recordatorio de la notación 
Recordamos que \(\hat{x}_{k,l}\) corresponde a la estimación de \(x_k\) utilizando las observaciones hasta tiempo \(l\), que son denotadas \(\left. y \right|_{1:l}\). Hasta ahora sólo se ha abordado el proceso de filtraje, por lo que solo se ha calculado \(\hat{x}_{k,k}\) o \(\hat{x}_{k, k-1}\); la estimación del estado \(x_k\) solo usa las observaciones hasta el estado \(k\), \(\left. y \right|_{1:k}\), o hasta el estado \(k-1\),   \(\left. y \right|_{1:k-1}\). En ciertas situaciones, sin embargo, es interesante mejorar una estimación incorporando observaciones obtenidas posteriormente, o de manera más técnica, calcular \(\hat{x}_{k, k+1}, \hat{x}_{k, k+2}, \hat{x}_{k, k+3}, \dots\). El proceso de obtener estas estimaciones usando datos de tiempos posteriores es llamado \textit{smoothing} o suavizado. El nombre se debe a que, al tener más información disponible, es posible generar estimaciones con menos ruido, más ``suaves''.

Hay tres escenarios comunes donde surge esta necesidad. El primero de ellos es el suavizado de punto fijo, donde se busca estimar un estado en un tiempo fijo, digamos \(j\), y el número de observaciones disponibles aumenta continuamente. Un ejemplo de esto podría ser. En este caso se intenta estimar \(\hat{x}_{j, j+1}, \hat{x}_{j, j+2}, \hat{x}_{j, j+3}, \dots\). Un segundo escenario es el suavizado con retardo fijo. En este caso, para cada estado \(k\) se tienen \(N\) observaciones posteriores, donde \(N\) es un número fijo. Se intenta estimar \(\hat{x}_{k, k+N}\) para \(k = 1, 2, \dots\). 

El último escenario es el que será utilizado en este trabajo, el suavizado con intervalo fijo. En este caso, se cuenta con un intervalo de \(M\) mediciones \(\left. y \right|_{1:M}\), y se busca la mejor estimación posible de todos los estados hasta tiempo \(M\), es decir, se quiere estimar \(\hat{x}_{0,M}, \hat{x}_{1,M}, \hat{x}_{2,M}, \dots, \hat{x}_{M,M}\). 

% Presentar tal vez un poco la idea de forward backward. Al menos creo que tendré que mostrar la notación. 

El suavizado de intervalo fijo suele realizarse en dos pasadas: la primera permite obtener estimaciones usando los datos pasados, y la segunda suaviza los resultados. Una de las formas más comunas es la de Rauch, Tung y Striebel \cite{Rauch1965}, conocida como \textit{RTS smoother}. Más detalles en el capítulo 9, \textit{Optimal Smoothing}, de \cite{Simon2006}. Para el sistema dado por \ref{eq:sistema-pre-suavizado}, el \textit{RTS smoother} hace una pasada ``hacia adelante'' o \textit{forward} mediante las ecuaciones\ref{eq:fordward} y luego una ``hacia atrás'' o \textit{backward} usando \ref{eq:backward}.
% Insertar un cuadrito




\begin{equation}\label{eq:sistema-pre-suavizado}
\begin{aligned}
x_k &= F_{k-1}x_{k-1} + w_{k-1} \\ 
y_k &= H_k x_k + v_k \\ 
w_k &\sim  \mathcal{N}(0, Q_k)\\
v_k &\sim  \mathcal{N}(0, R_k).
\end{aligned}
\end{equation}

\begin{enumerate}
    \item Inicializar el filtro \textit{forward}.
    
    \begin{equation}
    \begin{aligned}
    \hat{x}_{f0} &= \mathbb{E}(x_0) \\
    P^{+}_{f0} &= \mathbb{E}\left[(x_0 - \hat{x}_{f0})(x_0 - \hat{x}_{f0})^{\top}\right]. 
    \end{aligned}
    \end{equation}
    
    \item Para \(k = 1, \dots, N\) (donde \(N\) es el tiempo final), ejecutar el filtro \textit{forward}, que es simplemente el filtro de Kalman estándar. 
    
    \begin{equation}\label{eq:fordward}
    \begin{aligned}
    P^{-}_{fk} &= F_{k-1}P^{+}_{f,k-1}F_{k-1}^{\top} + Q_{k-1} \\ 
    K_{fk} &= P^{-}_{fk} H_k^{\top} (H_k P^{-}_{fk}H_k^{\top} + R_k)^{-1}  \\
    \hat{x}^{-}_{fk} &= F_{k-1}\hat{x}^{+}_{f,k-1}\\
    %\hat{x}^{-}_{fk} &= F_{k-1}\hat{x}^{+}_{f,k-1} + G_{k-1}u_{k-1} \<\
    \hat{x}^{+}_{fk} &= \hat{x}^{-}_{fk} + K_{fk} \left(y_k - H_k \hat{x}^{-}_{fk} \right)\\ 
    P^{+}_{fk} &= (I - K_{fk}H_k) P^{-}_{fk} (I-K_{fk}H_k)^{\top} + K_{fk}R_{k}K_{fk}^{\top} \\
    &= \left[ (P^{-}_{fk})^{-1} + H_k^{\top} R_{k}^{-1}H_k\right]^{-1} \\ 
    &= (I - K_{fk}H_k)P^{-}_{fk}.
    \end{aligned}
    \end{equation}
    
    \item Inicializar el \textit{RTS smooter} 
    \begin{equation}
    \begin{aligned}
    \hat{x}_{k} &= \hat{x}^{+}_{fN} \\
    P_k &= P^{+}_{fN}.
    \end{aligned}
    \end{equation}
    
    \item Para \(k = N-1, \dots, 1, 0\) ejecutar las ecuaciones del \textit{RTS smoother} 
    
    \begin{equation}\label{eq:backward}
    \begin{aligned}
    \mathcal{I}^{-}_{f, k+1} &= \left( P^{-}_{f, k+1}\right)^{-1} \\
    K_k &= P^{+}_{fk} F_{k}^{\top} \mathcal{I}^{-}_{f, k+1} \\
    P_k &= P^{+}_{fN} - K_k (P^{-}_{f, k+1} - P_{k+1})K_k^{\top} \\ 
    \hat{x}_k &= \hat{x}^{+}_{fk} + K_k(\hat{x}_{k+1} - \hat{x}^{-}_{f,k+1}).
    \end{aligned}
    \end{equation}
\end{enumerate}



\subsection{Restricciones: observaciones (casi) perfectas} \label{casiperfect}

El survey \cite{Simon2010} presenta varias alternativas para tratar con restricciones. La idea de la técnica de observaciones (casi) perfectas es la siguiente: en un sistema de la forma \(x_{k+1} = f_k(x_k) + w_k\), observado mediante una ecuación \(y_k = Hx_k + v_k \), se busca imponer una restricción \(|Dx - d| \leq \epsilon\). Esto se consigue ampliando la matriz de observaciones como muestra la ecuación \ref{eq:perfect-obs}. Si se busca una restricción fuerte con \(\epsilon = 0\), la técnica es llamada ``observaciones perfectas'', y si se busca una restricción suave con \(\epsilon > 0\), recibe el nombre de ``observaciones casi perfectas''.


\begin{equation}\label{eq:perfect-obs}
\begin{bmatrix}
y_k \\
d 
\end{bmatrix} = 
\begin{bmatrix}
H \\
D
\end{bmatrix} x_k
+
\begin{bmatrix}
v_k \\
\epsilon  
\end{bmatrix}.
\end{equation}




% Mostrar que es posible que el filtro converja a valores erróneos, ver cómo eso depende de los errores que se le dan al filtro.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{Recursos adicionales}\label{recursos-adicionales}

% \begin{itemize}
% \itemsep1pt\parskip0pt\parsep0pt
% \item
%   \href{https://www.kalmanfilter.net/default.aspx}{KalmanFilter.NET}
%   contiene explicaciones y tutoriales.
% \end{itemize}

% Un libro más matemático es

% \emph{Optimal Filtering} de Brian Anderson y John Moore.

% \begin{itemize}
% \itemsep1pt\parskip0pt\parsep0pt
% \item
%   Katzfussa, Stroudb, Wiklec, ``Understanding the Ensemble Kalman
%   Filter''
% \end{itemize}
